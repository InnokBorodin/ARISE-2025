{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models for disbalanced datasets\n",
    "Current notebook codes model training to predict heavily disbalanced joint type datasets (>.5 of all data belongs to one class).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import shutil\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torchvision.transforms import v2\n",
    "from torchvision import models\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_data(main_class: str, inp_path: str, out_path: str) -> None:\n",
    "    '''\n",
    "    For groups with disbalanced classes.\n",
    "    Create folders and copy data from minor classes to make minor model DataLoaders using ImageFolder.\n",
    "\n",
    "    Args:\n",
    "        main_class (str)\n",
    "        inp_path (str): path to input data\n",
    "        out_path (str): path to output data\n",
    "    '''\n",
    "    for cl in os.listdir(inp_path):\n",
    "        if cl == main_class:\n",
    "            continue\n",
    "        os.makedirs(os.path.join(out_path, cl), exist_ok=True)\n",
    "        for _, file_name in enumerate(os.listdir(os.path.join(inp_path, cl))):\n",
    "            shutil.copy(os.path.join(inp_path, cl, file_name), os.path.join(out_path, cl, file_name))\n",
    "\n",
    "def get_dataloaders(joint_type_and_param: str, main_class: str):\n",
    "    '''\n",
    "    Make 4 dataloaders for both binary and minor model\n",
    "    '''\n",
    "    # [0.485, 0.456, 0.406], [0.229, 0.224, 0.225] Normalization values for RESNet & EfficientNet\n",
    "    mean_list, std_list = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "\n",
    "    train_transform = v2.Compose([\n",
    "        v2.Resize((224, 224)),\n",
    "        v2.RandomRotation(15),\n",
    "        v2.RandomHorizontalFlip(p = 0.3),\n",
    "        v2.RandomVerticalFlip(p = 0.3),\n",
    "        v2.ToTensor(),\n",
    "        v2.Normalize(mean_list, std_list)\n",
    "    ])\n",
    "\n",
    "    val_transform = v2.Compose([\n",
    "        v2.Resize((224, 224)),\n",
    "        v2.RandomRotation(15),\n",
    "        v2.ToTensor(),\n",
    "        v2.Normalize(mean_list, std_list)\n",
    "    ])\n",
    "\n",
    "    '''data_root = os.path.join('dataset', 'json_split')\n",
    "    joint_type_and_param = 'DIP_jsn' # data for DIP joints, predicting JSN score\n",
    "    train, val = os.path.join(data_root, 'train', joint_type_and_param), os.path.join(data_root, 'test', joint_type_and_param) '''\n",
    "\n",
    "    data_root = os.path.join('dataset', 'custom_split_inv_clahe')\n",
    "    train, val = os.path.join(data_root, joint_type_and_param, 'train'), os.path.join(data_root, joint_type_and_param, 'test')\n",
    "\n",
    "    n_classes = max(len(os.listdir(train)), len(os.listdir(val)))\n",
    "\n",
    "    train_minor, val_minor = os.path.join(data_root, f'{joint_type_and_param}_minor_classes', 'train'), \\\n",
    "                            os.path.join(data_root, f'{joint_type_and_param}_minor_classes', 'test')\n",
    "    copy_data(main_class, train, train_minor)\n",
    "    copy_data(main_class, val, val_minor)\n",
    "\n",
    "    train_dataset_bin = torchvision.datasets.ImageFolder(train, train_transform)\n",
    "    val_dataset_bin = torchvision.datasets.ImageFolder(val, val_transform)\n",
    "\n",
    "    train_dataset_minor = torchvision.datasets.ImageFolder(train_minor, train_transform)\n",
    "    val_dataset_minor = torchvision.datasets.ImageFolder(val_minor, val_transform)\n",
    "\n",
    "    batch_size = 64\n",
    "    train_dataloader_bin = torch.utils.data.DataLoader(\n",
    "        train_dataset_bin, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "    val_dataloader_bin = torch.utils.data.DataLoader(\n",
    "        val_dataset_bin, batch_size=batch_size, shuffle=False, num_workers=8)\n",
    "\n",
    "    train_dataloader_minor = torch.utils.data.DataLoader(\n",
    "        train_dataset_minor, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "    val_dataloader_minor = torch.utils.data.DataLoader(\n",
    "        val_dataset_minor, batch_size=batch_size, shuffle=False, num_workers=8)\n",
    "\n",
    "    print(len(train_dataloader_bin), len(val_dataloader_bin), len(train_dataloader_minor), len(val_dataloader_minor))\n",
    "    return train_dataloader_bin, val_dataloader_bin, train_dataloader_minor, val_dataloader_minor, n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_input(input_tensor, title=''):\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array( [0.229, 0.224, 0.225])\n",
    "\n",
    "    image = input_tensor.permute(1, 2, 0).numpy()\n",
    "    image = std * image + mean\n",
    "    plt.imshow(image.clip(0, 1))\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    plt.pause(0.001)\n",
    "\n",
    "def visualise_batch(train_dataloader):\n",
    "    X_batch, y_batch = next(iter(train_dataloader))\n",
    "\n",
    "    for x_item, y_item in zip(X_batch, y_batch):\n",
    "        show_input(x_item, title={y_item})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_transform(labels, output_transform):\n",
    "    tr_type, majour_class = output_transform.split('_')\n",
    "    majour_class = int(majour_class)\n",
    "    if tr_type == 'bin':\n",
    "        for i in range(labels.shape[0]):\n",
    "            labels[i] = 1 if labels[i] == majour_class else 0\n",
    "    elif tr_type == 'minor':\n",
    "        for i in range(labels.shape[0]):\n",
    "            labels[i] = labels[i] - 1  if labels[i] > majour_class else labels[i]\n",
    "    else:\n",
    "        raise ValueError(f'Invalid transform type {tr_type}')\n",
    "    return labels\n",
    "\n",
    "def train_model(model, train_dataloader, val_dataloader, loss, optimizer, num_epochs, device, output_transform = None):\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        if epoch == 20:\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                dataloader = train_dataloader\n",
    "                #scheduler.step()\n",
    "                model.train()\n",
    "            else:\n",
    "                dataloader = val_dataloader\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.\n",
    "            running_acc = 0.\n",
    "\n",
    "            y_preds, y_trues = [], []\n",
    "            for inputs, labels in dataloader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    preds = model(inputs)\n",
    "                    if output_transform:\n",
    "                       labels = out_transform(labels, output_transform)\n",
    "                    loss_value = loss(preds, labels)\n",
    "                    distance_weight = torch.abs(preds.argmax(1) - labels) + 1\n",
    "                    ordinal_ce_loss = torch.mean(distance_weight * loss_value)\n",
    "                    preds_class = preds.argmax(dim=1)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        ordinal_ce_loss.backward()\n",
    "                        optimizer.step()\n",
    "                    else:\n",
    "                        y_preds.extend(preds_class.detach().cpu().tolist())\n",
    "                        y_trues.extend(labels.detach().cpu().tolist())\n",
    "\n",
    "                running_loss += loss_value.item()\n",
    "                running_acc += (preds_class == labels.data).float().mean()\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloader)\n",
    "            epoch_acc = running_acc / len(dataloader)\n",
    "            if phase == 'train':\n",
    "                train_acc = epoch_acc\n",
    "            else:\n",
    "                val_acc = epoch_acc\n",
    "                val_loss = epoch_loss\n",
    "\n",
    "        #if epoch % 10 == 0:\n",
    "         #   print('Epoch {},\\n    train accuracy: {:.4f},\\n    val accuracy: {:.4f}, f1: {:.4f}'.format(epoch+1, train_acc, val_acc, \\\n",
    "          #                                                                                               f1_score(y_trues, y_preds, average='micro')), flush = True)\n",
    "\n",
    "        if epoch == 0:\n",
    "            best_loss = val_loss\n",
    "            best_model = model ########\n",
    "        elif val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model = copy.deepcopy(model)\n",
    "\n",
    "    #print('Epoch {},\\n    train accuracy: {:.4f},\\n    val accuracy: {:.4f}, f1: {:.4f}'.format(epoch+1, train_acc, val_acc, \\\n",
    "     #                                                                                           f1_score(y_trues, y_preds, average='micro')), flush = True)\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_time_augmentations(preds, inputs, model):\n",
    "    inp_rot_p15 = v2.functional.rotate(inputs, 10)\n",
    "    inp_rot_m15 = v2.functional.rotate(inputs, -10)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds += model(v2.functional.horizontal_flip(inputs))\n",
    "        preds += model(v2.functional.horizontal_flip(inp_rot_p15))\n",
    "        preds += model(v2.functional.horizontal_flip(inp_rot_m15))\n",
    "        preds += model(inp_rot_p15)\n",
    "        preds += model(inp_rot_m15)\n",
    "    return preds\n",
    "\n",
    "def get_preds(preds, inputs, majour_class, minor_model):\n",
    "    majour_class = int(majour_class)\n",
    "    with torch.no_grad():\n",
    "        y_pred = torch.empty((preds.shape[0],))\n",
    "        for i, item in enumerate(inputs):\n",
    "            if torch.argmax(preds[i]).item() == 1:\n",
    "                y_pred[i] = majour_class\n",
    "            else:\n",
    "                pr = minor_model(item.unsqueeze(0))\n",
    "                pred = torch.argmax(pr).item()\n",
    "                y_pred[i] = pred if pred < majour_class else pred + 1\n",
    "    return y_pred\n",
    "\n",
    "def get_preds_tta(preds, inputs, majour_class, minor_model):\n",
    "    majour_class = int(majour_class)\n",
    "    with torch.no_grad():\n",
    "        y_pred = torch.empty((preds.shape[0],))\n",
    "        for i, item in enumerate(inputs):\n",
    "            if torch.argmax(preds[i]).item() == 1:\n",
    "                y_pred[i] = majour_class\n",
    "            else:\n",
    "                pr = minor_model(item.unsqueeze(0))\n",
    "                pr = test_time_augmentations(pr, item.unsqueeze(0), minor_model)\n",
    "                pred = torch.argmax(pr).item()\n",
    "                y_pred[i] = pred if pred < majour_class else pred + 1\n",
    "    return y_pred\n",
    "\n",
    "def predict_val(bin_model, minor_model, val_dataloader_bin, device, majour_class):\n",
    "    bin_model.eval()\n",
    "    minor_model.eval()\n",
    "    acc = 0\n",
    "    acc_tta = 0\n",
    "\n",
    "    y_preds, y_preds_tta, y_trues = [], [], []\n",
    "    for inputs, labels in val_dataloader_bin:\n",
    "        inputs = inputs.to(device)\n",
    "        y_trues.extend(labels.detach().cpu().tolist())\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds = bin_model(inputs)\n",
    "            \n",
    "        y_pred = get_preds(preds, inputs, majour_class, minor_model)\n",
    "        y_preds.extend(y_pred.detach().cpu().tolist())\n",
    "        acc += (y_pred==labels.data).float().mean()\n",
    "\n",
    "        y_pred_tta = get_preds_tta(test_time_augmentations(preds, inputs, bin_model), inputs, majour_class, minor_model)\n",
    "        y_preds_tta.extend(y_pred_tta.detach().cpu().tolist())\n",
    "        acc_tta += (y_pred_tta == labels.data).float().mean()\n",
    "\n",
    "    f1 = f1_score(y_trues, y_preds, average='micro')\n",
    "    f1_tta = f1_score(y_trues, y_preds_tta, average='micro')\n",
    "    print('Test accuracy = {:.4f}, f1 = {:.4f}'.format(acc/len(val_dataloader_bin), f1))\n",
    "    print('Test accuracy (with tta) = {:.4f}, f1 = {:.4f}'.format(acc_tta/len(val_dataloader_bin), f1_tta))\n",
    "    return acc/len(val_dataloader_bin), acc_tta/len(val_dataloader_bin), f1, f1_tta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bin_minor_models(n_classes):\n",
    "    #model = models.resnet34(weights = models.ResNet34_Weights.DEFAULT)\n",
    "    bin_model = models.efficientnet_b4(weights = models.EfficientNet_B4_Weights.DEFAULT)\n",
    "    minor_model = models.efficientnet_b4(weights = models.EfficientNet_B4_Weights.DEFAULT)\n",
    "    \n",
    "    for param in bin_model.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in minor_model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    #for ResNet\n",
    "    '''model.fc = torch.nn.Sequential(torch.nn.Dropout(p = 0.2, inplace=True),\n",
    "                                    torch.nn.Linear(model.fc.in_features, model.fc.in_features//2),\n",
    "                                    torch.nn.Dropout(p = 0.2, inplace=True),\n",
    "                                    torch.nn.LeakyReLU(),\n",
    "                                    torch.nn.Linear(model.fc.in_features//2, n_classes)) '''\n",
    "    # For EfficientNet\n",
    "    bin_model.classifier = torch.nn.Sequential(torch.nn.Dropout(p = 0.2, inplace=True),\n",
    "                                        torch.nn.Linear(bin_model.classifier[1].in_features, bin_model.classifier[1].in_features//2),\n",
    "                                        torch.nn.Dropout(p = 0.2, inplace=True),\n",
    "                                        torch.nn.LeakyReLU(),\n",
    "                                        torch.nn.Linear(bin_model.classifier[1].in_features//2, 2))\n",
    "    minor_model.classifier = torch.nn.Sequential(torch.nn.Dropout(p = 0.2, inplace=True),\n",
    "                                        torch.nn.Linear(minor_model.classifier[1].in_features, minor_model.classifier[1].in_features//2),\n",
    "                                        torch.nn.Dropout(p = 0.2, inplace=True),\n",
    "                                        torch.nn.LeakyReLU(),\n",
    "                                        torch.nn.Linear(minor_model.classifier[1].in_features//2, n_classes-1))\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    #print(f'Using {device}')\n",
    "    minor_model = minor_model.to(device)\n",
    "    bin_model = bin_model.to(device)\n",
    "\n",
    "    loss_bin = torch.nn.CrossEntropyLoss()\n",
    "    loss_minor = torch.nn.CrossEntropyLoss()\n",
    "    bin_optimizer = torch.optim.Adam(bin_model.parameters(), lr=3.0e-4)\n",
    "    minor_optimizer = torch.optim.Adam(minor_model.parameters(), lr=3.0e-4)\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    #currently the scheduler is disabled in 'train_model' function\n",
    "    #scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "    return bin_model, loss_bin, bin_optimizer, minor_model, loss_minor, minor_optimizer, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DIP_erosion': '0', 'CMC_erosion': '0', 'wrist_erosion': 'balanced', 'RC_erosion': '0', 'ulna_erosion': '0', 'PIP_erosion': '0', 'MCP_erosion': '0'}\n",
      "{'DIP_jsn': 'balanced', 'CMC_jsn': 'balanced', 'wrist_jsn': 'balanced', 'RC_jsn': 'balanced', 'ulna_jsn': '0', 'PIP_jsn': 'balanced', 'MCP_jsn': 'balanced'}\n"
     ]
    }
   ],
   "source": [
    "def count_disbalance(df, param):\n",
    "    '''\n",
    "    Decide if classes in group are disbalanced or not\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): erosion or jsn dataframe\n",
    "        param (str): 'jsn' or 'erosion'\n",
    "    '''\n",
    "    d = {}\n",
    "    for column in df.columns:\n",
    "        vals = df[column].to_list()\n",
    "        s = sum(vals)\n",
    "        for i, v in enumerate(vals):\n",
    "            if v > s * .5:\n",
    "                d[f'{column}_{param}'] = str(i)\n",
    "                break\n",
    "        else:\n",
    "            d[f'{column}_{param}'] = 'balanced'\n",
    "    return d\n",
    "\n",
    "erosion_df = pd.read_csv(os.path.join('dataset', 'non-sorted', 'erosion_data_counts.csv'), header = 0, index_col=0)\n",
    "jsn_df = pd.read_csv(os.path.join('dataset', 'non-sorted', 'jsn_data_counts.csv'), header = 0, index_col=0)\n",
    "er_d, jsn_d = count_disbalance(erosion_df, 'erosion'), count_disbalance(jsn_df, 'jsn')\n",
    "print(er_d)\n",
    "print(jsn_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " DIP_erosion, majour class - 0\n",
      "40 8 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\diffusion_nn\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n",
      "100%|██████████| 80/80 [39:39<00:00, 29.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training bin model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [09:14<00:00,  6.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training minor model\n",
      "Test accuracy = 0.9799, f1 = 0.9821\n",
      "Test accuracy (with tta) = 0.9777, f1 = 0.9802\n",
      "\n",
      " CMC_erosion, majour class - 0\n",
      "32 7 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\diffusion_nn\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n",
      "100%|██████████| 80/80 [40:34<00:00, 30.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training bin model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [09:12<00:00,  6.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training minor model\n",
      "Test accuracy = 0.9603, f1 = 0.9876\n",
      "Test accuracy (with tta) = 0.9683, f1 = 0.9900\n",
      "\n",
      " RC_erosion, majour class - 0\n",
      "8 2 2 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\diffusion_nn\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n",
      "100%|██████████| 80/80 [12:20<00:00,  9.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training bin model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [10:04<00:00,  7.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training minor model\n",
      "Test accuracy = 0.7081, f1 = 0.7745\n",
      "Test accuracy (with tta) = 0.7368, f1 = 0.8039\n",
      "\n",
      " ulna_erosion, majour class - 0\n",
      "8 2 2 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\diffusion_nn\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n",
      "100%|██████████| 80/80 [12:36<00:00,  9.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training bin model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [09:58<00:00,  7.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training minor model\n",
      "Test accuracy = 0.6891, f1 = 0.7500\n",
      "Test accuracy (with tta) = 0.6969, f1 = 0.7596\n",
      "\n",
      " PIP_erosion, majour class - 0\n",
      "32 7 2 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\diffusion_nn\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n",
      "100%|██████████| 80/80 [39:49<00:00, 29.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training bin model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [09:42<00:00,  7.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training minor model\n",
      "Test accuracy = 0.8535, f1 = 0.9429\n",
      "Test accuracy (with tta) = 0.8580, f1 = 0.9479\n",
      "\n",
      " MCP_erosion, majour class - 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\diffusion_nn\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 8 7 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [45:34<00:00, 34.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training bin model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [12:12<00:00,  9.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training minor model\n",
      "Test accuracy = 0.7966, f1 = 0.8088\n",
      "Test accuracy (with tta) = 0.8048, f1 = 0.8167\n"
     ]
    }
   ],
   "source": [
    "full_dict = dict(list(er_d.items()) + list(jsn_d.items()))\n",
    "\n",
    "for key in full_dict:\n",
    "    if key == 'ulna_jsn': #consisted only of class '0'\n",
    "        continue\n",
    "    if full_dict[key] != 'balanced':\n",
    "        majour_class = full_dict[key]\n",
    "        print(f'\\n {key}, majour class - {majour_class}')\n",
    "\n",
    "        train_dataloader_bin, val_dataloader_bin, train_dataloader_minor, val_dataloader_minor, n_classes = get_dataloaders(key, full_dict[key])\n",
    "        bin_model, loss_bin, bin_optimizer, minor_model, loss_minor, minor_optimizer, device = get_bin_minor_models(n_classes)\n",
    "\n",
    "        bin_model = train_model(bin_model, train_dataloader_bin, val_dataloader_bin, loss_bin, bin_optimizer, num_epochs = 80,\n",
    "                                 device = device, output_transform = f'bin_{majour_class}')\n",
    "        print('Finished training bin model')\n",
    "        minor_model = train_model(minor_model, train_dataloader_minor, val_dataloader_minor, loss_minor, minor_optimizer, num_epochs = 80,\n",
    "                                 device = device, output_transform = f'minor_{majour_class}')\n",
    "        print('Finished training minor model')\n",
    "\n",
    "        val_acc, val_acc_tta, f1, f1_tta = predict_val(bin_model, minor_model, val_dataloader_bin, device, majour_class)\n",
    "        \n",
    "        #check for model name\n",
    "        torch.save(bin_model, os.path.join('models', \\\n",
    "                        'bin_effNetb4_{}_{:.3f}_tta_{:.3f}.json'.format(key, val_acc, val_acc_tta)))\n",
    "        torch.save(minor_model, os.path.join('models', \\\n",
    "                        'minor_effNetb4_{}_{:.3f}_tta_{:.3f}.json'.format(key, val_acc, val_acc_tta)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion_nn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
