{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARISE-2025\n",
    "\n",
    "This hackathon was originally made for joint detection and classification. \n",
    "My part of work was to build classification pipeline. Classification was divided into two different categories: joint erosion (6 classes) and joint space narrowing (5 classes).\n",
    "\n",
    "In this file I'm building train and val image preprocessing pipeline for all classifiers:\n",
    "1. transforming scores table: originally it consisted from scores from 3 experts, so in order to get classes we have to take an average of all labels\n",
    "2. merge bounding_box and scores dataframes\n",
    "3. use bounding box data from merged dataframe to transform images and sort them based on scores data\n",
    "4. count classes for all data groups. This will bw necessary to find class disbalance\n",
    "5. split images to train and val directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score table transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_scores(input_file: str, output_file: str) -> None:\n",
    "    \"\"\"\n",
    "    Transform the raw scores data into the desired format.\n",
    "\n",
    "    Args:\n",
    "        input_file (str): Path to the input CSV file.\n",
    "        output_file (str): Path to save the transformed CSV file.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(input_file)\n",
    "    \n",
    "    df.drop(\"expert_id\", axis=1, inplace=True)\n",
    "    df = df.rename(columns={df.columns[0]: \"joint_id\"})\n",
    "    df[\"finger\"] = df[\"finger\"].fillna(\"none\")\n",
    "    df = df.dropna(subset=[\"score\"])\n",
    "\n",
    "    grouped = df.groupby([\"joint_id\", \"patient_id\", \"hand\", \"joint\", \"finger\", \"disease\"], dropna=False)[\"score\"].mean().reset_index()\n",
    "    grouped[\"score\"] = grouped[\"score\"].round()\n",
    "\n",
    "    pivoted = grouped.pivot_table(\n",
    "        index=[\"joint_id\", \"patient_id\", \"hand\", \"joint\", \"finger\"],\n",
    "        columns=\"disease\",\n",
    "        values=\"score\",\n",
    "        fill_value=0\n",
    "    ).reset_index()\n",
    "\n",
    "    pivoted.columns.name = None \n",
    "    pivoted = pivoted.rename(columns={\"erosion\": \"erosion_score\", \"JSN\": \"jsn_score\"})\n",
    "    pivoted.sort_values(by=[\"patient_id\", \"joint_id\"], ascending=[False, True], inplace=True)\n",
    "\n",
    "    pivoted.to_csv(output_file, index=False)\n",
    "    print(f\"Transformed data saved to {output_file}\")\n",
    "\n",
    "transform_scores('dataset/scores.csv', 'dataset/avg_scores.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging bounding box and scores tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(bbox_file: str, score_file: str, output_file: str) -> None:\n",
    "    '''\n",
    "    merge bbox.csv & score.csv\n",
    "    save result to output_file\n",
    "\n",
    "    Args:\n",
    "        bbox_file (str): path to file with bounding boxes\n",
    "        score_file (str): path to file with scores for each joint\n",
    "        output_file (str): path to output file\n",
    "    '''\n",
    "    bbox_df = pd.read_csv(bbox_file)\n",
    "    score_df = pd.read_csv(score_file)\n",
    "    \n",
    "    bbox_df.drop(columns=[\"finger\"], inplace=True)\n",
    "    score_df.drop(columns=[\"finger\"], inplace=True)\n",
    "    \n",
    "    bbox_df.rename(columns={\"Unnamed: 0\": \"joint_id\"}, inplace=True)\n",
    "    bbox_df[\"joint_id\"] = bbox_df[\"joint_id\"].apply(lambda x: x % 42)\n",
    "    \n",
    "    \n",
    "    merged_df = pd.merge(\n",
    "        score_df,\n",
    "        bbox_df,\n",
    "        left_on=['joint_id', 'patient_id', 'hand', 'joint'],\n",
    "        right_on=['joint_id', 'patient_id', 'hand', 'joint'],\n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    merged_df.to_csv(output_file, index=False)\n",
    "    print('Merged file saves successfully')\n",
    "\n",
    "merge('dataset/bboxes.csv', 'dataset/avg_scores.csv', 'dataset/merged_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cropping and saving images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_and_save_images(merged_df, image_dir, output_dir, normalized=False):\n",
    "    \"\"\"\n",
    "    Crop images based on bounding boxes and save them to a specific folder based on their label and joint type.\n",
    "\n",
    "    Cropped images of one group of joints from one patient will have equal sizes, this way torchvision.transforms.Reshape will not deform relative size of joint space,\n",
    "    thus increasing model predictive quality.\n",
    "\n",
    "    Args:\n",
    "        merged_df (pd.DataFrame): Merged DataFrame containing bbox and label information.\n",
    "        image_dir (str): Path to the directory containing input images.\n",
    "        output_dir (str): Path to save the cropped images.\n",
    "        normalized (bool): Whether the bounding box coordinates are normalized.\n",
    "    \"\"\"             \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for _, row in merged_df.iterrows():\n",
    "        image_name = str(row[\"patient_id\"]) + \".jpeg\"  # Assuming the image name is in a column called \"image_name\"\n",
    "        joint_type = row['joint']\n",
    "        erosion_score, jsn_score = int(row['erosion_score']), int(row['jsn_score'])\n",
    "        label = f\"{int(row['erosion_score'])}_{int(row['jsn_score'])}\"\n",
    "        x_center, y_center, width, height = row[\"xcenter\"], row[\"ycenter\"], row[\"dx\"], row[\"dy\"]\n",
    "\n",
    "        os.makedirs(os.path.join(output_dir, f'{joint_type}_erosion', str(erosion_score)), exist_ok = True)\n",
    "        os.makedirs(os.path.join(output_dir, f'{joint_type}_jsn', str(jsn_score)), exist_ok = True)\n",
    "        # Load the image\n",
    "        image_path = os.path.join(image_dir, image_name)\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"Image not found: {image_path}\")\n",
    "            continue\n",
    "\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"Failed to load image: {image_path}\")\n",
    "            continue\n",
    "\n",
    "        # Get image dimensions\n",
    "        img_height, img_width = image.shape[:2]\n",
    "\n",
    "        # Convert normalized coordinates to pixel coordinates if necessary\n",
    "        if normalized:\n",
    "            x_center *= img_width\n",
    "            y_center *= img_height\n",
    "            width *= img_width\n",
    "            height *= img_height\n",
    "\n",
    "        # Calculate bounding box coordinates\n",
    "        x1 = max(int(x_center - width / 2), 0)\n",
    "        y1 = max(int(y_center - height / 2), 0)\n",
    "        x2 = min(int(x_center + width / 2), img_width)\n",
    "        y2 = min(int(y_center + height / 2), img_height)\n",
    "\n",
    "        # Crop the image\n",
    "        cropped_image = image[y1:y2, x1:x2]\n",
    "\n",
    "        # Save the cropped image\n",
    "        output_name = f\"{os.path.splitext(image_name)[0]}_{row['joint_id']}_{label}.jpg\"\n",
    "        output_path_1 = os.path.join(output_dir, f'{joint_type}_erosion', str(erosion_score), output_name)\n",
    "        output_path_2 = os.path.join(output_dir, f'{joint_type}_jsn', str(jsn_score), output_name)\n",
    "        try:\n",
    "            cv2.imwrite(output_path_1, cropped_image)\n",
    "            cv2.imwrite(output_path_2, cropped_image)\n",
    "        except:\n",
    "            print(cropped_image.shape)\n",
    "            print(row)\n",
    "            return 0\n",
    "    print('Saved cropped images successfully')\n",
    "\n",
    "# Load the CSV files\n",
    "label_df = pd.read_csv('dataset/merged_df.csv')\n",
    "\n",
    "#set bounding boxes sizes equal for each joint type\n",
    "for id, sub_df in label_df.groupby('patient_id'):\n",
    "    sub_df['dx'] = sub_df.groupby('joint')['dx'].transform('max')\n",
    "    sub_df['dy'] = sub_df.groupby('joint')['dy'].transform('max')\n",
    "\n",
    "# Crop and save images\n",
    "crop_and_save_images(label_df, os.path.join('dataset','jpeg_inv_clahe'), os.path.join('dataset','non-sorted_inv_clahe'), False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count classes for all data groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = pd.read_csv('dataset/merged_df.csv')\n",
    "\n",
    "joint_types = label_df['joint'].unique()\n",
    "erosion_df = pd.DataFrame(columns = joint_types, index = range(6))\n",
    "jsn_df = pd.DataFrame(columns = joint_types, index = range(5))\n",
    "\n",
    "# if a class has any samples in it, corresponding folder will exist\n",
    "\n",
    "for joint in joint_types:\n",
    "    for i in range(6):\n",
    "        path = os.path.join('dataset', 'non-sorted_inv_clahe', f'{joint}_erosion', str(i))\n",
    "        if os.path.exists(path):\n",
    "            erosion_df.loc[i, joint] = len(os.listdir(path))\n",
    "        else:\n",
    "            erosion_df.loc[i, joint] = 0\n",
    "\n",
    "for joint in joint_types:\n",
    "    for i in range(5):\n",
    "        path = os.path.join('dataset', 'non-sorted_inv_clahe', f'{joint}_jsn', str(i))\n",
    "        if os.path.exists(path):\n",
    "            jsn_df.loc[i, joint] = len(os.listdir(path))\n",
    "        else:\n",
    "            jsn_df.loc[i, joint] = 0\n",
    "\n",
    "jsn_df.to_csv(os.path.join('dataset', 'non-sorted_inv_clahe', 'jsn_data_counts.csv'))\n",
    "erosion_df.to_csv(os.path.join('dataset', 'non-sorted_inv_clahe', 'erosion_data_counts.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erosion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join('dataset', 'custom_split_inv_clahe'), exist_ok=True)\n",
    "\n",
    "for dir in os.listdir(os.path.join('dataset', 'non-sorted_inv_clahe')):\n",
    "    # splitting data to train and val. Every 6-th image goes to val data\n",
    "    try:\n",
    "        for cl in os.listdir(os.path.join('dataset', 'non-sorted_inv_clahe', dir)):\n",
    "            os.makedirs(os.path.join('dataset', 'custom_split_inv_clahe', dir, 'train', str(cl)), exist_ok=True)\n",
    "            os.makedirs(os.path.join('dataset', 'custom_split_inv_clahe', dir, 'val', str(cl)), exist_ok=True)\n",
    "\n",
    "            for i, file_name in enumerate(tqdm(os.listdir(os.path.join('dataset', 'non-sorted_inv_clahe', dir, cl)))):\n",
    "                img = Image.open(os.path.join('dataset', 'non-sorted_inv_clahe', dir, cl, file_name))\n",
    "\n",
    "                if i % 6 != 0:\n",
    "                    img.save(os.path.join('dataset', 'custom_split_inv_clahe', dir, 'train', str(cl), file_name))\n",
    "                else:\n",
    "                    img.save(os.path.join('dataset', 'custom_split_inv_clahe', dir, 'val', str(cl), file_name))\n",
    "\n",
    "    except NotADirectoryError:\n",
    "        # this exception was made, because jsn and erosion counts DataFrames are stored in dataset/non-sorted\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion_nn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
