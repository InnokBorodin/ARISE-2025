{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed data saved to dataset/avg_scores.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def transform_scores(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Transform the raw scores data into the desired format.\n",
    "\n",
    "    Args:\n",
    "        input_file (str): Path to the input CSV file.\n",
    "        output_file (str): Path to save the transformed CSV file.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(input_file)\n",
    "    \n",
    "    df.drop(\"expert_id\", axis=1, inplace=True)\n",
    "    df = df.rename(columns={df.columns[0]: \"joint_id\"})\n",
    "    df[\"finger\"] = df[\"finger\"].fillna(\"none\")\n",
    "    df = df.dropna(subset=[\"score\"])\n",
    "\n",
    "    grouped = df.groupby([\"joint_id\", \"patient_id\", \"hand\", \"joint\", \"finger\", \"disease\"], dropna=False)[\"score\"].mean().reset_index()\n",
    "    grouped[\"score\"] = grouped[\"score\"].round()\n",
    "\n",
    "    pivoted = grouped.pivot_table(\n",
    "        index=[\"joint_id\", \"patient_id\", \"hand\", \"joint\", \"finger\"],\n",
    "        columns=\"disease\",\n",
    "        values=\"score\",\n",
    "        fill_value=0\n",
    "    ).reset_index()\n",
    "\n",
    "    pivoted.columns.name = None \n",
    "    pivoted = pivoted.rename(columns={\"erosion\": \"erosion_score\", \"JSN\": \"jsn_score\"})\n",
    "    pivoted.sort_values(by=[\"patient_id\", \"joint_id\"], ascending=[False, True], inplace=True)\n",
    "\n",
    "    pivoted.to_csv(output_file, index=False)\n",
    "    print(f\"Transformed data saved to {output_file}\")\n",
    "\n",
    "transform_scores('dataset/scores.csv', 'dataset/avg_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged file saves successfully\n"
     ]
    }
   ],
   "source": [
    "def merge(bbox_file, score_file, output_file):\n",
    "    bbox_df = pd.read_csv(bbox_file)\n",
    "    score_df = pd.read_csv(score_file)\n",
    "    \n",
    "    bbox_df.drop(columns=[\"finger\"], inplace=True)\n",
    "    score_df.drop(columns=[\"finger\"], inplace=True)\n",
    "    \n",
    "    bbox_df.rename(columns={\"Unnamed: 0\": \"joint_id\"}, inplace=True)\n",
    "    bbox_df[\"joint_id\"] = bbox_df[\"joint_id\"].apply(lambda x: x % 42)\n",
    "    \n",
    "    \n",
    "    merged_df = pd.merge(\n",
    "        score_df,\n",
    "        bbox_df,\n",
    "        left_on=['joint_id', 'patient_id', 'hand', 'joint'],\n",
    "        right_on=['joint_id', 'patient_id', 'hand', 'joint'],\n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    merged_df.to_csv(output_file, index=False)\n",
    "    print('Merged file saves successfully')\n",
    "\n",
    "merge('dataset/bboxes.csv', 'dataset/avg_scores.csv', 'dataset/merged_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cropped images successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Function to crop and save images\n",
    "def crop_and_save_images(merged_df, image_dir, output_dir, normalized=False, split_subsets_by_id=None):\n",
    "    \"\"\"\n",
    "    Crop images based on bounding boxes and save them with the appropriate label.\n",
    "\n",
    "    Args:\n",
    "        merged_df (pd.DataFrame): Merged DataFrame containing bbox and label information.\n",
    "        image_dir (str): Path to the directory containing input images.\n",
    "        output_dir (str): Path to save the cropped images.\n",
    "        normalized (bool): Whether the bounding box coordinates are normalized.\n",
    "    \"\"\"\n",
    "    if split_subsets_by_id is not None:\n",
    "        id_to_split = {}\n",
    "        with open(split_subsets_by_id, \"r\") as f:\n",
    "            split_file = json.load(f)\n",
    "        for split_name in split_file.keys():\n",
    "            os.makedirs(os.path.join(output_dir, split_name), exist_ok=True)\n",
    "            for value in split_file[split_name]:\n",
    "                id_to_split[value] = split_name\n",
    "                  \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for _, row in merged_df.iterrows():\n",
    "        image_name = str(row[\"patient_id\"]) + \".jpeg\"  # Assuming the image name is in a column called \"image_name\"\n",
    "        img_split = id_to_split[row[\"patient_id\"]]\n",
    "        joint_type = row['joint']\n",
    "        erosion_score, jsn_score = int(row['erosion_score']), int(row['jsn_score'])\n",
    "        label = f\"{int(row['erosion_score'])}_{int(row['jsn_score'])}\"\n",
    "        x_center, y_center, width, height = row[\"xcenter\"], row[\"ycenter\"], row[\"dx\"], row[\"dy\"]\n",
    "\n",
    "        os.makedirs(os.path.join(output_dir, img_split, f'{joint_type}_erosion', str(erosion_score)), exist_ok = True)\n",
    "        os.makedirs(os.path.join(output_dir, img_split, f'{joint_type}_jsn', str(jsn_score)), exist_ok = True)\n",
    "        # Load the image\n",
    "        image_path = os.path.join(image_dir, image_name)\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"Image not found: {image_path}\")\n",
    "            continue\n",
    "\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"Failed to load image: {image_path}\")\n",
    "            continue\n",
    "\n",
    "        # Get image dimensions\n",
    "        img_height, img_width = image.shape[:2]\n",
    "\n",
    "        # Convert normalized coordinates to pixel coordinates if necessary\n",
    "        if normalized:\n",
    "            x_center *= img_width\n",
    "            y_center *= img_height\n",
    "            width *= img_width\n",
    "            height *= img_height\n",
    "\n",
    "        # Calculate bounding box coordinates\n",
    "        x1 = max(int(x_center - width / 2), 0)\n",
    "        y1 = max(int(y_center - height / 2), 0)\n",
    "        x2 = min(int(x_center + width / 2), img_width)\n",
    "        y2 = min(int(y_center + height / 2), img_height)\n",
    "\n",
    "        # Crop the image\n",
    "        cropped_image = image[y1:y2, x1:x2]\n",
    "\n",
    "        # Save the cropped image\n",
    "        output_name = f\"{os.path.splitext(image_name)[0]}_{row['joint_id']}_{label}.jpg\"\n",
    "        output_path_1 = os.path.join(output_dir, img_split, f'{joint_type}_erosion', str(erosion_score), output_name)\n",
    "        output_path_2 = os.path.join(output_dir, img_split, f'{joint_type}_jsn', str(jsn_score), output_name)\n",
    "        try:\n",
    "            cv2.imwrite(output_path_1, cropped_image)\n",
    "            cv2.imwrite(output_path_2, cropped_image)\n",
    "        except:\n",
    "            print(cropped_image.shape)\n",
    "            print(row)\n",
    "            return 0\n",
    "    print('Saved cropped images successfully')\n",
    "\n",
    "# Load the CSV files\n",
    "label_df = pd.read_csv('dataset/merged_df.csv')\n",
    "\n",
    "#set bounding boxes sizes equal for each joint type\n",
    "for id, sub_df in label_df.groupby('patient_id'):\n",
    "    sub_df['dx'] = sub_df.groupby('joint')['dx'].transform('max')\n",
    "    sub_df['dy'] = sub_df.groupby('joint')['dy'].transform('max')\n",
    "\n",
    "# Crop and save images\n",
    "crop_and_save_images(label_df, os.path.join('dataset','jpeg'), 'dataset', False, os.path.join('dataset','train_val_split.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cropped images successfully\n"
     ]
    }
   ],
   "source": [
    "# custom data split\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Function to crop and save images\n",
    "def crop_and_save_images(merged_df, image_dir, output_dir, normalized=False):\n",
    "    \"\"\"\n",
    "    Crop images based on bounding boxes and save them with the appropriate label.\n",
    "\n",
    "    Args:\n",
    "        merged_df (pd.DataFrame): Merged DataFrame containing bbox and label information.\n",
    "        image_dir (str): Path to the directory containing input images.\n",
    "        output_dir (str): Path to save the cropped images.\n",
    "        normalized (bool): Whether the bounding box coordinates are normalized.\n",
    "    \"\"\"             \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for _, row in merged_df.iterrows():\n",
    "        image_name = str(row[\"patient_id\"]) + \".jpeg\"  # Assuming the image name is in a column called \"image_name\"\n",
    "        joint_type = row['joint']\n",
    "        erosion_score, jsn_score = int(row['erosion_score']), int(row['jsn_score'])\n",
    "        label = f\"{int(row['erosion_score'])}_{int(row['jsn_score'])}\"\n",
    "        x_center, y_center, width, height = row[\"xcenter\"], row[\"ycenter\"], row[\"dx\"], row[\"dy\"]\n",
    "\n",
    "        os.makedirs(os.path.join(output_dir, f'{joint_type}_erosion', str(erosion_score)), exist_ok = True)\n",
    "        os.makedirs(os.path.join(output_dir, f'{joint_type}_jsn', str(jsn_score)), exist_ok = True)\n",
    "        # Load the image\n",
    "        image_path = os.path.join(image_dir, image_name)\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"Image not found: {image_path}\")\n",
    "            continue\n",
    "\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"Failed to load image: {image_path}\")\n",
    "            continue\n",
    "\n",
    "        # Get image dimensions\n",
    "        img_height, img_width = image.shape[:2]\n",
    "\n",
    "        # Convert normalized coordinates to pixel coordinates if necessary\n",
    "        if normalized:\n",
    "            x_center *= img_width\n",
    "            y_center *= img_height\n",
    "            width *= img_width\n",
    "            height *= img_height\n",
    "\n",
    "        # Calculate bounding box coordinates\n",
    "        x1 = max(int(x_center - width / 2), 0)\n",
    "        y1 = max(int(y_center - height / 2), 0)\n",
    "        x2 = min(int(x_center + width / 2), img_width)\n",
    "        y2 = min(int(y_center + height / 2), img_height)\n",
    "\n",
    "        # Crop the image\n",
    "        cropped_image = image[y1:y2, x1:x2]\n",
    "\n",
    "        # Save the cropped image\n",
    "        output_name = f\"{os.path.splitext(image_name)[0]}_{row['joint_id']}_{label}.jpg\"\n",
    "        output_path_1 = os.path.join(output_dir, f'{joint_type}_erosion', str(erosion_score), output_name)\n",
    "        output_path_2 = os.path.join(output_dir, f'{joint_type}_jsn', str(jsn_score), output_name)\n",
    "        try:\n",
    "            cv2.imwrite(output_path_1, cropped_image)\n",
    "            cv2.imwrite(output_path_2, cropped_image)\n",
    "        except:\n",
    "            print(cropped_image.shape)\n",
    "            print(row)\n",
    "            return 0\n",
    "    print('Saved cropped images successfully')\n",
    "\n",
    "# Load the CSV files\n",
    "label_df = pd.read_csv('dataset/merged_df.csv')\n",
    "\n",
    "#set bounding boxes sizes equal for each joint type\n",
    "for id, sub_df in label_df.groupby('patient_id'):\n",
    "    sub_df['dx'] = sub_df.groupby('joint')['dx'].transform('max')\n",
    "    sub_df['dy'] = sub_df.groupby('joint')['dy'].transform('max')\n",
    "\n",
    "# Crop and save images\n",
    "crop_and_save_images(label_df, os.path.join('dataset','jpeg_inv_clahe'), os.path.join('dataset','non-sorted_inv_clahe'), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DIP</th>\n",
       "      <th>CMC</th>\n",
       "      <th>wrist</th>\n",
       "      <th>RC</th>\n",
       "      <th>ulna</th>\n",
       "      <th>PIP</th>\n",
       "      <th>MCP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842</td>\n",
       "      <td>1040</td>\n",
       "      <td>88</td>\n",
       "      <td>128</td>\n",
       "      <td>600</td>\n",
       "      <td>274</td>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>749</td>\n",
       "      <td>259</td>\n",
       "      <td>42</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>492</td>\n",
       "      <td>437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1184</td>\n",
       "      <td>703</td>\n",
       "      <td>158</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "      <td>1130</td>\n",
       "      <td>1330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>218</td>\n",
       "      <td>377</td>\n",
       "      <td>239</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>480</td>\n",
       "      <td>633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>73</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    DIP   CMC wrist   RC ulna   PIP   MCP\n",
       "0   842  1040    88  128  600   274   434\n",
       "1   749   259    42   47    0   492   437\n",
       "2  1184   703   158  149    0  1130  1330\n",
       "3   218   377   239  229    0   480   633\n",
       "4     7    21    73   47    0    24   166"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "label_df = pd.read_csv('dataset/merged_df.csv')\n",
    "\n",
    "joint_types = label_df['joint'].unique()\n",
    "erosion_df = pd.DataFrame(columns = joint_types, index = range(6))\n",
    "jsn_df = pd.DataFrame(columns = joint_types, index = range(5))\n",
    "\n",
    "for joint in joint_types:\n",
    "    for i in range(6):\n",
    "        path = os.path.join('dataset', 'non-sorted_inv_clahe', f'{joint}_erosion', str(i))\n",
    "        if os.path.exists(path):\n",
    "            erosion_df.loc[i, joint] = len(os.listdir(path))\n",
    "        else:\n",
    "            erosion_df.loc[i, joint] = 0\n",
    "\n",
    "for joint in joint_types:\n",
    "    for i in range(5):\n",
    "        path = os.path.join('dataset', 'non-sorted_inv_clahe', f'{joint}_jsn', str(i))\n",
    "        if os.path.exists(path):\n",
    "            jsn_df.loc[i, joint] = len(os.listdir(path))\n",
    "        else:\n",
    "            jsn_df.loc[i, joint] = 0\n",
    "\n",
    "#jsn_df.to_csv(os.path.join('dataset', 'non-sorted_inv_clahe', 'jsn_data_counts.csv'))\n",
    "#erosion_df.to_csv(os.path.join('dataset', 'non-sorted_inv_clahe', 'erosion_data_counts.csv'))\n",
    "\n",
    "jsn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DIP</th>\n",
       "      <th>CMC</th>\n",
       "      <th>wrist</th>\n",
       "      <th>RC</th>\n",
       "      <th>ulna</th>\n",
       "      <th>PIP</th>\n",
       "      <th>MCP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2954</td>\n",
       "      <td>2378</td>\n",
       "      <td>292</td>\n",
       "      <td>478</td>\n",
       "      <td>470</td>\n",
       "      <td>2290</td>\n",
       "      <td>2465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>17</td>\n",
       "      <td>155</td>\n",
       "      <td>42</td>\n",
       "      <td>81</td>\n",
       "      <td>71</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>92</td>\n",
       "      <td>34</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    DIP   CMC wrist   RC ulna   PIP   MCP\n",
       "0  2954  2378   292  478  470  2290  2465\n",
       "1    27    17   155   42   81    71   333\n",
       "2    15     3    92   34   26    27   154\n",
       "3     2     0    10   19    2     7    11\n",
       "4     1     0     1   11    2     2     5\n",
       "5     1     2    50   16   19     3    32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "erosion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DIP_erosion': '0', 'CMC_erosion': '0', 'wrist_erosion': 'balanced', 'RC_erosion': '0', 'ulna_erosion': '0', 'PIP_erosion': '0', 'MCP_erosion': '0'}\n",
      "{'DIP_jsn': 'balanced', 'CMC_jsn': 'balanced', 'wrist_jsn': 'balanced', 'RC_jsn': 'balanced', 'ulna_jsn': '0', 'PIP_jsn': 'balanced', 'MCP_jsn': 'balanced'}\n"
     ]
    }
   ],
   "source": [
    "def count_disbalance(df, param):\n",
    "    d = {}\n",
    "    for column in df.columns:\n",
    "        vals = df[column].to_list()\n",
    "        s = sum(vals)\n",
    "        for i, v in enumerate(vals):\n",
    "            if v > s * .5:\n",
    "                d[f'{column}_{param}'] = str(i)\n",
    "                break\n",
    "        else:\n",
    "            d[f'{column}_{param}'] = 'balanced'\n",
    "    return d\n",
    "\n",
    "print(count_disbalance(erosion_df, 'erosion'))\n",
    "print(count_disbalance(jsn_df, 'jsn'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2378/2378 [00:09<00:00, 257.94it/s]\n",
      "100%|██████████| 17/17 [00:00<00:00, 175.07it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 240.78it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 348.31it/s]\n",
      "100%|██████████| 1040/1040 [00:02<00:00, 376.02it/s]\n",
      "100%|██████████| 259/259 [00:00<00:00, 428.03it/s]\n",
      "100%|██████████| 703/703 [00:01<00:00, 403.35it/s]\n",
      "100%|██████████| 377/377 [00:00<00:00, 394.79it/s]\n",
      "100%|██████████| 21/21 [00:00<00:00, 535.55it/s]\n",
      "100%|██████████| 2954/2954 [00:11<00:00, 253.08it/s]\n",
      "100%|██████████| 27/27 [00:00<00:00, 263.61it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 245.11it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 284.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 172.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 186.12it/s]\n",
      "100%|██████████| 842/842 [00:02<00:00, 397.87it/s]\n",
      "100%|██████████| 749/749 [00:02<00:00, 366.36it/s]\n",
      "100%|██████████| 1184/1184 [00:03<00:00, 334.72it/s]\n",
      "100%|██████████| 218/218 [00:00<00:00, 374.12it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 292.08it/s]\n",
      "100%|██████████| 2465/2465 [00:10<00:00, 224.11it/s]\n",
      "100%|██████████| 333/333 [00:01<00:00, 231.95it/s]\n",
      "100%|██████████| 154/154 [00:00<00:00, 232.71it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 201.30it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 205.64it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 242.36it/s]\n",
      "100%|██████████| 434/434 [00:01<00:00, 224.26it/s]\n",
      "100%|██████████| 437/437 [00:01<00:00, 227.05it/s]\n",
      "100%|██████████| 1330/1330 [00:07<00:00, 180.45it/s]\n",
      "100%|██████████| 633/633 [00:02<00:00, 234.95it/s]\n",
      "100%|██████████| 166/166 [00:00<00:00, 235.94it/s]\n",
      "100%|██████████| 2290/2290 [00:11<00:00, 192.78it/s]\n",
      "100%|██████████| 71/71 [00:00<00:00, 260.42it/s]\n",
      "100%|██████████| 27/27 [00:00<00:00, 266.80it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 208.85it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 285.11it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 196.15it/s]\n",
      "100%|██████████| 274/274 [00:00<00:00, 363.78it/s]\n",
      "100%|██████████| 492/492 [00:01<00:00, 342.19it/s]\n",
      "100%|██████████| 1130/1130 [00:03<00:00, 343.70it/s]\n",
      "100%|██████████| 480/480 [00:01<00:00, 344.37it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 332.88it/s]\n",
      "100%|██████████| 478/478 [00:02<00:00, 231.81it/s]\n",
      "100%|██████████| 42/42 [00:00<00:00, 233.33it/s]\n",
      "100%|██████████| 34/34 [00:00<00:00, 231.44it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 224.49it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 226.53it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 222.64it/s]\n",
      "100%|██████████| 128/128 [00:01<00:00, 109.89it/s]\n",
      "100%|██████████| 47/47 [00:00<00:00, 229.22it/s]\n",
      "100%|██████████| 149/149 [00:00<00:00, 234.88it/s]\n",
      "100%|██████████| 229/229 [00:00<00:00, 242.19it/s]\n",
      "100%|██████████| 47/47 [00:00<00:00, 233.76it/s]\n",
      "100%|██████████| 470/470 [00:01<00:00, 248.91it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 258.44it/s]\n",
      "100%|██████████| 26/26 [00:00<00:00, 259.55it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 221.81it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 246.46it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 248.79it/s]\n",
      "100%|██████████| 600/600 [00:01<00:00, 351.96it/s]\n",
      "100%|██████████| 292/292 [00:02<00:00, 144.54it/s]\n",
      "100%|██████████| 155/155 [00:00<00:00, 170.34it/s]\n",
      "100%|██████████| 92/92 [00:00<00:00, 157.25it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 171.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 98.18it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 151.38it/s]\n",
      "100%|██████████| 88/88 [00:00<00:00, 142.22it/s]\n",
      "100%|██████████| 42/42 [00:00<00:00, 155.04it/s]\n",
      "100%|██████████| 158/158 [00:01<00:00, 144.64it/s]\n",
      "100%|██████████| 239/239 [00:01<00:00, 164.73it/s]\n",
      "100%|██████████| 73/73 [00:00<00:00, 159.38it/s]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.makedirs(os.path.join('dataset', 'custom_split_inv_clahe'), exist_ok=True)\n",
    "\n",
    "for dir in os.listdir(os.path.join('dataset', 'non-sorted_inv_clahe')):\n",
    "    try:\n",
    "        for cl in os.listdir(os.path.join('dataset', 'non-sorted_inv_clahe', dir)):\n",
    "            os.makedirs(os.path.join('dataset', 'custom_split_inv_clahe', dir, 'train', str(cl)), exist_ok=True)\n",
    "            os.makedirs(os.path.join('dataset', 'custom_split_inv_clahe', dir, 'test', str(cl)), exist_ok=True)\n",
    "            for i, file_name in enumerate(tqdm(os.listdir(os.path.join('dataset', 'non-sorted_inv_clahe', dir, cl)))):\n",
    "                img = Image.open(os.path.join('dataset', 'non-sorted_inv_clahe', dir, cl, file_name))\n",
    "                if i % 6 != 0:\n",
    "                    img.save(os.path.join('dataset', 'custom_split_inv_clahe', dir, 'train', str(cl), file_name))\n",
    "                else:\n",
    "                    img.save(os.path.join('dataset', 'custom_split_inv_clahe', dir, 'test', str(cl), file_name))\n",
    "    except NotADirectoryError:\n",
    "        continue\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion_nn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
